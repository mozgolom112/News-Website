# [Проект №1][1]: *"Новостной сайт"* #

+ *__Инструменты__:* Python, Flask, PostgreSQL, REACT(?)

___

+ *__Описание__*:

*1. Отображение:*
Новостной сайт __стилизированный под газету__.
Новостные статьи должны иметь __разбивку на категории__. На главной странице содержится __навигационная панель__, с основными категориями. Новости отображаются в виде колонок по 3, изначально __отображено 9 статей__. Необходимо добавить __пагинацию__ по 9 статей. Присутствует поисковая строка, для поиска статей. На каждую новость можно перейти, и посмотреть подробнее, с возможностью оставить комментарии для авторизированных пользователь. 

 *2. Техническая реализация:*
Все статьи, __загружены из интернета с помощью API__, __сохраняются в базе данных__ (далее БД) и __отдаются пользователю именно из БД__. __Регистрация пользователя__ должна __давать следующее приемущества__: сохранение статей, комментирование, отображение по тегам, которые интересны пользователю, т.е. автоматическое отображение на главной странице. __Поиск статей__ должен осуществляться по *заголовкам, дате, источникам*.
___

+ *__Реализация классов__*:

 1. У каждой __новости__ должны быть следующие поля:  
*UUID, название, краткое описание, полный текст, дата публикации, дата редактирования, источник, теги, ссылки на картинки, количество просмотров, комментарии, количество комментариев*. Возможны расширения.

 2. У каждого __пользователя__ должны быть следующие поля:
*фамилия, имя, отчество, логин, пароль, понравишиеся статьи, популярные теги, сохраненные статьи*. Возможны расширения.

___

*База данных:*
+ новости:
__Бизнес логика__: 
1) *Топ-заголовки*
    На главной странице странице отображаются топ-заголовки. Они будут актуальны в течении 24 часов и будут обнавляться каждые 30 минут. Обновление будет происходить следующим образом: 
    1) отправляем запрос к newsapi.org, через api __top headlines__ 
    2) делаем выборку из таблицы *News* по ключу "Search_query" со значением "TH" - что означает *Top headings*.
    3) так как статей будет не очень много (не более 200), проверяем* на совпадение из новых и выборки из БД
    Проверка* описана ниже
    4) если есть, то игнорируем, если нет то добавляем с значением "TH"
    5) попутно проверяем актуальность статьи. Если она опубликована позже чем 24 часа, то меняем значение ключа "Search_query" на "NA", что означет *Need to archive* - необходимость добавление* в архив. 
    Добавление "Top-headings" будет описано ниже*
2) *Поиск пользователей*
    Для авторизованных пользователей мы будем сохранять результаты поиска в нашей базе данных в течении 24 часов, а также подкачивать актуальные новости, и обновлять счетчик времени. Т.е. если пользователь, повторил запрос в течении 24 часов после прошлого, то будут автоматически догружены* новые новости. Для неавторизованных, мы будем выкачивать новости напрямую с api (хоть это и не выгодно экономически, но пока для авторизированных пользователей мы экономим ресурсы памяти и по скорости, т.к. мы выкачиваем только актуальные новости, и отдаем старые напрямую из БД). Логика состоит в следующем:
    1) авторизированный пользователь делает запрос
    2) мы осуществляем поиск по таблице *Search_queries* и смотрим, делал ли авторизированные пользователи такой запрос.
        2.1.1)  если да, то обращаемся к newsapi.org через api *Everything*, с параметром from, в котором указана дата последнего запроса по этой статье из таблицы *Search_queries* по ключу last_time_update (-15 минут, так как мы пользуемся бесплатной версией)
        2.1.2) отправляем все новые статьи пользователю и загружаем старые из БД
        2.1.3) загружаем новые статьи в БД и обнавляем last_time_update.
    
        2.2.1) если нет, то обращаемся к newsapi.org через api *Everything*, с запросом пользователя
        2.2.2) отдаем результаты пользователю
        2.2.3) сохраняем результаты в базе данных
    3) проверяем на актуальность запроса. Если он не был повторно вызван в течении 24 часов, то добавляем* их в БД.
    Добавление пользовательских запросов в БД будет описано ниже*

  __Функции__:
  1) Проверка top-headings новостей:
  Делаем выборку из таблицы *News*, где в ключе "Search_query" стоит "TH". И по ней производим следующую проверку:
    + сравнение по дате и времени - да, идем дальше, нет - добавляем 
        + сравнение id источника - да, идем дальше, нет - добавляем
            + сравнение заголовков - да, бракуем, нет - добавляем, и закидываем в лог-файл.
Если совпало по времени, можно предположить, что в одно и тоже время новость выложили два новостных агенства. Если совпали и источник происхождения новости, значит стоит проверить заголовки. 
2) Добавление top-headings новостей после истечения актуальности:
Аналогично фукнции проверки top-headings. Поиск по всем статьям из таблицы *News*. Так как их не очень много, то можно позволить себе это.
3) Добавление пользовательских запросов:
К сожалению, пока аналогично двум выше. Если есть совпадение, то в ключ "keywords" добавляем этот запрос. Если этой статьи нет, то меняем Search_query на занчение "A" - код архива.

Cтруктура:
   


[1]: https://github.com/mozgolom112/News-Website